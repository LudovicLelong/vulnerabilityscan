---
sidebar_position: 2
title: "Utiliser spider classique pour trouver toutes les urls associées qu'il y a sur une page internet"
---


## Le code besoin dans le main pour lancer l'analyse 

Je vous donne ici le code pour que ca marche en local sans pour l'instant parler d'API, qu'il y aura après et qui nous servira de communiquer entre notre front (site visuel) et le back.

```
package main

import (
	"fmt"
	"time"
	"vulnerabilityscan/zap-spider-url"
)

func main() {
	zapClient := zap_spider_url.NewZAPv2()

	fmt.Printf("Spider target %s\n", zap_spider_url.Target)

	// Utiliser le Traditional Spider Scan
	scanID, err := zapClient.SpiderScan()
	if err != nil {
		fmt.Println("Erreur lors du démarrage du Traditional Spider:", err)
		return
	}
	fmt.Printf("Scan ID: %s\n", scanID)

	timeout := time.Now().Add(2 * time.Minute)
	for {
		status, err := zapClient.SpiderStatus(scanID)
		if err != nil {
			fmt.Println("Erreur lors de la vérification du statut du Spider:", err)
			return
		}
		if status == "100" { // Vérifiez si le Spider est à 100%
			fmt.Println("Spider a terminé à 100%")
			break
		}
		if time.Now().After(timeout) {
			fmt.Println("Timeout atteint")
			break
		}
		fmt.Printf("Spider status: %s%%\n", status) // Affiche le pourcentage de progression
		time.Sleep(2 * time.Second)
	}

	fmt.Println("Spider completed")
	results, err := zapClient.SpiderResults(0, 100)
	if err != nil {
		fmt.Println("Erreur lors de l'obtention des résultats du Spider:", err)
		return
	}

	fmt.Printf("Nombre de résultats du Spider: %d\n", len(results))
	fmt.Println("Spider results:", results)
}

```

et le fichier spider.go : 

```
package zap_spider_url

import (
	"encoding/json"
	"fmt"
	"net/url"
)

func (zap *ZAPv2) SpiderScan() (string, error) {
	params := url.Values{}
	params.Add("url", Target)

	body, err := zap.Request("/JSON/spider/action/scan/", params)
	if err != nil {
		return "", err
	}

	fmt.Println("Response from Traditional Spider Scan:", string(body)) // Log supplémentaire

	var result map[string]interface{}
	if err := json.Unmarshal(body, &result); err != nil {
		return "", err
	}

	scanID, ok := result["scan"].(string)
	if !ok {
		return "", fmt.Errorf("failed to start traditional spider scan")
	}

	return scanID, nil
}

func (zap *ZAPv2) SpiderStatus(scanID string) (string, error) {
	params := url.Values{}
	params.Add("scanId", scanID)

	body, err := zap.Request("/JSON/spider/view/status/", params)
	if err != nil {
		return "", err
	}

	fmt.Println("Response from Spider Status:", string(body)) // Log supplémentaire

	var status SpiderStatus
	if err := json.Unmarshal(body, &status); err != nil {
		return "", err
	}

	return status.Status, nil
}

func (zap *ZAPv2) SpiderResults(start, count int) ([]string, error) { // Changer le type de retour ici
	params := url.Values{}
	params.Add("start", fmt.Sprintf("%d", start))
	params.Add("count", fmt.Sprintf("%d", count))

	body, err := zap.Request("/JSON/spider/view/results/", params)
	if err != nil {
		return nil, err
	}

	fmt.Println("Response from Spider Results:", string(body)) // Log supplémentaire

	var results SpiderResults
	if err := json.Unmarshal(body, &results); err != nil {
		return nil, err
	}

	return results.Results, nil // Changer le type de retour ici
}

```

Pour que ca marche il faut changer dans . > zap-spider-url > zap :
!["Image de code pour remplir zap api key"](./img/zap-apikey-field.png)
Remplir et mettre sa bonne clé d'API, son bon numéro de port localhost, et le site internet ("Target") dont on veut trouver tous ces liens.

Quand on lance le résultat on tombe sur un tableau avec toutes les url trouvé sur la page : 
!["Tableau résultat spider"](./img/tableau-resultat.png)

Pour allé plus loin : [Utiliser spider Ajax](spider-ajax.md) .